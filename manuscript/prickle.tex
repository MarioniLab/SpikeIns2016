\documentclass{article}
\usepackage[margin=3cm]{geometry}
\usepackage{textcomp}
\usepackage{graphicx}
\usepackage{float}
\usepackage[font={small,it}]{caption}
\usepackage{amsmath}

\title{When normalization gets prickly: are spike-ins good enough for single-cell RNA sequencing data?}
\author{Aaron Lun}

\begin{document}

\maketitle

\section{Introduction}
Single-cell RNA sequencing (scRNA-seq) is a powerful technique for studying transcriptional activity in individual cells.
Briefly, RNA is isolated from single cells, converted into cDNA and sequenced using massively parallel sequencing technologies \cite{shapiro2013singlecell}.
This can be done on microfluidics platforms, or increasingly, with plate-based protocols such as Smart-seq2 \cite{picelli2014full} that are compatible with existing techniques like indexed fluorescence-activated cell sorting (FACS).
Gene expression can be quantified by mapping the read sequences to the genome and counting the number of reads mapped to each gene.
To avoid amplification biases, individual transcript molecules can be tagged with unique molecular identifiers (UMIs) \cite{islam2014quantitative}, such that sequencing to saturation and counting UMIs will yield the number of transcripts of each gene in a cell.
%However, sequencing to saturation may not be economically feasible for hundreds or thousands of cells.
However, not all molecules will be captured and sequenced due to cell-specific inefficiencies in reverse transcription \cite{stegle2015computational}.
The presence of these cell-specific biases compromises the use of the read/UMI count as a quantitative measure of gene expression.
Some normalization is necessary to remove these biases before counts can be meaningfully compared between cells.

One commonly used normalization strategy is to use a set of genes that have constant expression across cells.
This set can consist of pre-defined ``house-keeping'' genes, or it can be empirically defined under the assumption that most genes are not differentially expressed (DE) between cells.
Counts are scaled to eliminate (presumably artifactual) differences in the coverage of this set across cells.
This removes spurious differences like those caused by composition bias, i.e., where greater sequencing of upregulated transcripts proportionally reduces the sequencing of all other genes \cite{robinson2010tmm}.
The scaled counts can then be compared between libraries.
This gene-based approach works well for bulk sequencing experiments where the population-wide gene expression profile is stable.
However, it may not be suitable for single-cell experiments where technical noise and biological heterogeneity complicate the identification of a non-DE set. 
For example, house-keeping genes may be turned on or off by transcriptional bursting \cite{marinov2014singlecell}, while cell cycling and other processes may trigger large-scale changes in the transcriptional programme that preclude the assumption of a non-DE majority.

An alternative normalization strategy involves the use of spike-in RNA for which the identity and quantity of all transcripts is known \cite{stegle2015computational}.
The same volume of spike-in RNA solution is added to each cell and processed along with the cellular transcripts.
This yields a set of read or UMI counts for both cellular and spike-in genes in each cell.
Normalization is performed by scaling the counts for each cell such that the counts for the spike-in genes are, on average, the same between cells.
The central assumption of this approach is that the same amount of spike-in RNA is added to each cell.
Thus, any differences in the coverage of the spike-in genes between cells must be artifactual in origin and should be removed by scaling.
The use of spike-ins for normalization seems preferable as it avoids making strong assumptions about the biology of single cells.
However, a major criticism of this approach in bulk experiments is that the volume of spike-in RNA cannot be consistently added to each sample \cite{robinson2010tmm}.
Variable addition of spike-in RNA would mean that the assumption of equal spike-ins betwen cells is violated, compromising the effectiveness of normalization \cite{risso2014normalization}.
Another criticism is that synthetic spike-in transcripts may not behave in the same manner as the cellular transcripts \cite{grun2015design}.
This means that any cell-specific biases in the latter may not be captured by the former.

In this paper, we conduct a series of experiments to estimate the reliability of spike-in normalization in single-cell transcriptome studies employing plate-based protocols.
We use mixtures of two distinct spike-in RNA sets to quantify the variability of the added spike-in volume across cells.
We also characterize the variability in behaviour between the two sets, to determine if cell-specific biases change between different RNA populations.
Both factors are quantitatively negligible and have only minor effects on the results of downstream analyses such as detection of DE and highly variable genes.
These results suggest that spike-ins can be safely used for routine normalization of scRNA-seq data.

% The advantage of spike-ins is that it can capture cell size and doesn't require a non-DE majority.
% However, is the cell size interesting, or should it be normalized out (in which case accurate spike-in addition wouldn't be required at all)?
% It's most obviously useful for cell cycle considerations -- possibly also cancer and in some aspects of differentiation.
% The Islam non-UMI dataset is one example where there seems to be a 20-50-fold increase in counts in the MEFs vs mESCs.
% 
% I guess spike-in normalization is more technically correct, even if you end up getting every gene as being DE (technically true in terms of molecules, but possibly irrelevant).
% Rankings definitely change - spike-in normalization would favour genes that are upregulated on top of an increase in RNA content (as these would be hugely significant).
% Standard normalization would have no preference as you seek the balance between the two extremes.
% On the other hand, any non-DE genes with no change in the molecule number will be called as significant in standard normalization, which is definitively wrong.
% You could have your cake and eat it by separating the DE list into up/down changes for easier examination of the up/down changes.

\section{Results}

\subsection{Overview of the mixture experiments}
We used two spike-in sets -- the External RNA Controls Consortium (ERCC) set and the Spike-in RNA Variants (SIRV) set.
Equal volumes of each spike-in set were added into a well and converted into a library with the Smart-seq2 protocol.
This process was repeated for multiple wells, and sequencing was performed on all of the generated libraries.
For each library, reads were mapped back to the genome and counted into genes.
The total count across all genes was computed for each spike-in set, and the log-ratio of the total counts between the two sets was calculated (denoted here as $\theta_i$).
The variance of this log-ratio across wells contains the variance in the addition of each spike-in volume $\sigma_{vol}^2$;
    variance in the behaviour of each spike-in set $\mbox{var}(\log \phi_{is})$, where $\phi_{is}$ represents the relative capture efficiency of transcripts in set $s$;
    and additional technical variability from library preparation and sequencing $\sigma^2_{lib(s)}$.
In other words, for $s=1$ (ERCC) and 2 (SIRV), the variance of $\theta_i$ can be decomposed to 
\[
    \mbox{var}(\theta_i) = 2\sigma_{vol}^2 + \sigma^2_{lib(1)} + \sigma^2_{lib(2)} + \mbox{var}(\log \phi_{i1}) +  \mbox{var}(\log \phi_{i2}) \;.
\]

The experiment was repeated after mixing the two spike-in sets before addition into each well. 
The variance of the log-ratio of the total counts of the two spike-in sets was then computed across wells (denoted here as $\theta_i'$).
Here, the ratio of the added volumes of two spike-in sets is constant across all wells.
This means that variability in volume addition will not contribute to variability of $\theta_i'$, i.e.,
\[
    \mbox{var}(\theta_i') = \sigma^2_{lib(1)} + \sigma^2_{lib(2)} + \mbox{var}(\log \phi_{i1}) +  \mbox{var}(\log \phi_{i2}) \;.
\]
Subtracting the estimated variance from that of the first experiment yields an estimate of $\sigma_{vol}^2$.
It is also possible to achieve further decomposition of the variance by considering the variance of the log-ratios between transcripts in the same spike-in set.
The assumption is that, on average, different transcripts from the same spike-in set will have the same capture efficiency.
Any variance should be solely due to technical variability -- this allows $\sigma^2_{lib(1)} + \sigma^2_{lib(2)}$ to be estimated and subtracted from $\mbox{var}(\theta_i')$ to obtain $\mbox{var}(\log \phi_{i1}) +  \mbox{var}(\log \phi_{i2})$.
The latter is useful as it represents the variability in the relative capture efficiency (and thus, cell-specific bias) between the different spike-in sets.

Both experiments were performed with a cell in each well, sourced from a homogeneous cell line.
The log-ratio between spike-in and cellular counts was computed for each well.
The variance of this log-ratio across wells includes the biological variability in total RNA across cells.
This serves as a reference to which the spike-in-based components of the technical variability can be compared. 

A schematic of the experimental design is provided in Figure~\ref{fig:expdesign}.
The mathematical framework underlying the variance decomposition is described in Section~1 of the Supplementary Materials.

% It should be stressed that the specific choice of population does not matter.
% Once the variance is estimated, it can be applied to other studies involving different RNA populations.

\begin{figure}[H]
\begin{center}
%\includegraphics[width=0.8\textwidth]{expdesign.pdf}
\end{center}
\caption{Proposed experimental design to assess the variability of spike-ins.
The first experiment (A) involves adding an equal volume of each spike-in population (red or blue) into each well, and sequencing each well.
The variance in the log-ratios of the populations across wells represents the technical variability of the spike-in procedure.
The second experiment (B) involves adding an equal volume of a pooled mixture of the two spike-ins into each well, and sequencing each well.
Here, the variance represents the specific variability introduced by library generation and sequencing.
The third experiment (C) involves adding an equal volume of one spike-in population (red) into each well with RNA from a single cell, and sequencing each well.
This measures the overall variability, including the biological variability in the total RNA of each cell.
Components of the variability can be separated by comparing the variances of the log-ratios.
}
\label{fig:expdesign}
\end{figure}

\section{Evaluating the effect of spike-in variability on existing software}
The effect of variable spike-in quantities can be more rigorously evaluated in the context of downstream analyses.
Popular analyses include detection of DE genes between two or more biological conditions, and clustering of cells based on their expression profiles to identify distinct subpopulations.
We propose to assess the effect of spike-in variability on the behaviour of these analyses.
More specifically, we aim to determine whether each analysis is sensitive to realistic violations of the assumption of equal spike-in quantities.

DE detection can be performed using established methods for bulk data like edgeR \cite{robinson2010edgeR} or DESeq \cite{anders2010differential}, or with dedicated single-cell methods like Monocle \cite{trapnell2014dynamics} and SAMstrt \cite{katayama2013samstrt}.
The performance of each method can be described in terms of detection power (i.e., detection of truly DE genes) and control of the error rate (i.e., false detection of non-DE genes).
We plan to simulate single-cell gene counts where the spike-in quantity in each sample varies randomly, based on the estimated variability from previous experiments.
This simulation will involve multiple cells across different biological conditions, with some DE genes introduced as true positives.
We will apply each method to detect these DE genes, where normalization uses the assumption of equal spike-in quantities.
The effect of spike-in variability on performance can then be evaluated.

Clustering of cells is often done informally through dimensionality-reduction techniques such as Principal Component Analysis (PCA) or t-Distributed Stochastic Neighbor Embedding (t-SNE) \cite{van2008visualizing,julia2015sincell}.
This collapses the relative positioning of cells in high-dimensional expression space to a 2- or 3-dimensional representation from which distinct clusters can be more easily identified. 
Each cluster is interpretated as a subpopulation that may be of biological interest, e.g., a different cell type, cycling or apoptotic cells.
We propose to simulate expression data for several subpopulations of cells with variable spike-in quantities.
We normalize expression values under the assumption of equal spike-in quantities, and then we identify clusters from the normalized data with PCA and t-SNE.
Of particular concern is whether spike-in variability reduces the separation between the clusters for different subpopulations, or even results in the formation of spurious clusters.

\section{Integrating spike-in variability in DE analyses}
Most statistical pipelines for DE analyses assume that the scaling factors used in normalization are known.
They fail to account for uncertainty in the estimation of these factors, which may result in suboptimal performance when the spike-in quantities are variable.
However, this kind of uncertainty can be easily incorporated in a Bayesian framework.
In particular, the BASIC software package performs a Bayesian DE analysis for single-cell data \cite{cata?}.
We propose to augment the statistical routines in this package to account for the estimated variability in the spike-ins, and to assess the effect of doing so on performance.
We also plan to check whether the estimated variability of the spike-ins changes significantly between runs.
If not, the first and second experiments in Figure~\ref{fig:expdesign} can be done once for any given system.
The variability estimate can then be re-used for all analyses that use the same spike-in and sequencing protocol.
Otherwise, the experiments must be repeated for each study, to obtain an appropriate variability estimate that point in time.


%The final experiment uses RNA from single cells to gauge the effect of variable spike-ins on the detection of DE genes.
%Two homogeneous cell lines are chosen for sequencing, with multiple cells for each line and spike-ins added to each cell.
%The data is used for a DE analysis, using statistical methods that don't use spike-ins; do use spike-ins, but don't account for variability in the added volume; or do use spike-ins, and account for variable volume.
%Performance evaluation is based on the number of DE genes detected between cell lines (true positives) against that detected within cell lines (false positives).
%We hope to show that considering the variability in the spike-in quantity will improve DE detection.


\newpage

\section{Simulating the effect of spike-in variability}

\subsection{Overview}
The aim is to determine whether results are sensitive to spike-in variability, for downstream analyses that depend on the assumption of constant spike-ins.
Simulations are prepared from real data sets containing counts for spike-in transcripts.
Specifically, the added volume/capture efficiency of spike-ins for each well is resampled and the spike-in counts are rescaled to reflect this new volume or efficiency.
The results of the analysis on the simulated data are then compared to the original results.
Any changes indicate that the analysis is sensitive to spike-in variability.
The advantage of this approach is that it only modifies the scale of the spike-in counts -- the counts for the cellular genes are used directly and do not need to be simulated.

\subsection{Simulation design}
For each data set, the sum of the spike-in counts (i.e., the spike-in total) was computed for each cell.
The variance of the log$_2$-transformed spike-in totals across cells includes technical noise; variability in sequencing depth and capture efficiency between wells; and the variance of spike-in addition and population-specific behaviour.
The final component (denoted here as $s^2$) represents spike-in variability and must be removed prior to simulation.
Otherwise, resampling will introduce variance for addition/behaviour on top of what is already present, leading to overrepresentation of $s^2$ in the variance of the simulated totals.
Removal was achieved by scaling the log$_2$-totals such that the variance across wells was reduced by $s^2$ without changing the mean.
The scaled log-values were then transformed back to ``processed'' totals that contain no variability due to addition or behaviour.

The simulation was performed by sampling a new value for the combined addition/efficiency effect in each cell.
Specifically, the effect for each cell was sampled independently from a $2^X$ distribution where $X \sim \mathcal{N}(0, s^2)$.
This was used to scale the processed total to obtain a simulated total for each cell.
Counts for individual spike-in transcripts were then scaled to reflect this new total in each cell.
In this manner, the variance due to addition or efficiency is re-incorporated into the variance of the simulated totals across cells.

To scale the counts, a quantile adjustment approach was used to preserve the mean-variance relationship of the data.
A generalized linear model (GLM) was fitted to the counts across all cells for each spike-in gene, using the mglmOneGroup function in edgeR \cite{mccarthy2012differential, robinson2010edgeR} with an all-intercept design matrix.
An abundance-dependent trend was also fitted to the NB dispersions across all spike-in genes using the estimateDisp function.
In both cases, the original log-totals were used as the offsets for all cells.
The fitted GLM value and dispersion for each gene were treated as the true parameters of the NB distribution used to sample the observed count in each cell.
The simulated mean count for each gene in each cell was computed by taking the exponential of the sum of the log-simulated total for that cell and the GLM coefficient for that gene.
This was used as the mean of a simulated NB distribution, using the same value for the dispersion.
The quantile of each original count in its true distribution was mapped to a quantile in the simulated distribution, using the q2qnbinom function \cite{robinson2008small}.
This new quantile was used as the simulated count for the corresponding gene and cell.

% For simplicity, we assume that sequencing is performed to saturation in each data set, e.g., like UMIs.
% Thus, variability in the added volume will directly translate to variability in the total spike-in count.
% It also means that we do not have to rescale the cellular counts to reflect variable undersampling.
% Doing so would be problematic, as direct scaling of the counts would distort the empirical mean-variance relationship of the count data.

% The estimation of the true parameters conditions on the observed spike-in totals, and doesn't make the assumption that spike-in totals are constant.
% For example, if it turned out that you added half the amount of spike-in to one well, it wouldn't distort the estimation of the (conditional) mean.
% Okay, maybe the trended dispersion would be a bit weird, because technical variability should depend on the amount of RNA, but some inaccuracy there is forgivable.

The value of $s^2$ was set based on the estimated values for $\sigma^2_{vol} = X$ and $\mbox{var}(\psi_{is})$ in the previous section.
Technically, only the sum of $\mbox{var}(\psi_{is})$ across both spike-in populations was estimated 
    -- this is assumed to be evenly split between populations to obtain $\mbox{var}(\psi_{is}) = X$ for each $s$.
The sum of the variance components for addition and efficiency is then equal to $X$.
Thus, $s^2$ was set to $X$ to provide a realistic simulation.

\subsection{Implementation of downstream analyses}

\subsubsection{Detecting differential expressed genes}
Two scRNA-seq data sets were obtained -- one from a study with mouse embryonic stem cells (mESCs) and fibroblasts \cite{islam2011characterization} and another from a study with root epidermal and root center \textit{Arabidopsis Thaliana} cells \cite{brennecke2013accounting}.
In each study, DE genes were detected between cell types using edgeR \cite{lund2012detecting} and monocle \cite{trapnell2014dynamics}.
The former represents methods designed for analyses of bulk RNA-seq data, while the latter represents specialized single-cell methods.
For each method, spike-in normalization was performed by scaling the counts such that the spike-in totals were the same between cells.
The set of DE genes in the original data was then identified at a FDR of 5\% (see Section~Y in the Supplementary Materials for implementation details of each method).
This was repeated for the simulated data, and the proportion of genes common to both the original and simulated sets was computed.
The proportion of common genes in the top set of 20-2000 genes with the smallest $p$-values was also computed between the original and simulated analyses.
This was repeated for 10 simulation iterations, and the average proportions across iterations were reported for each method.

\subsubsection{Ranking highly variable genes}
Three scRNA-seq data sets were obtained -- one from a study of mouse haematopoietic stem cells \cite{wilson2015combined}, one from a study of murine immune cells \cite{brennecke2013accounting} and another from a study of mESCs \cite{islam2014quantitative}.
In each data set, highly variable genes (HVGs) were detected using two approaches based on spike-ins (see Section~Y in the Supplementary Materials for implementation details of each method).
The first approach is based on the method of Brennecke \textit{et al.} \cite{brennecke2013accounting} where the squared coefficient of variation for each gene is tested for a significant increase above technical noise.
The top set of HVGs was identified as those genes with the smallest $p$-values.
The second approach examines the variance of the log-counts, which provides some more robustness against outlier expression patterns.
Here, the top set of HVGs was identified as those with the largest biological components of the variance.
For both methods, the top set of 20-2000 genes was compared between the original and simulated analyses.
This was repeated for 10 simulation iterations, and the average proportions across iterations were reported for each method.

\subsubsection{Dimensionality reduction and clustering}
A scRNA-seq data set was obtained from a study of mESCs cultured under different conditions \cite{kolod2015single}.
A PCA plot was constructed from the original log-counts after spike-in normalization.
This was repeated for each simulation iteration, and the position of each cell on the simulated plot was mapped back to the corresponding location on the original plot.
In this manner, the sensitivity of the cell placement to spike-in variability was assessed.
Hierarchical clustering was also performed on the normalized log-counts using Euclidean distances or rank correlations.
The stability of each cluster was assessed based on the number of occurrences of that cluster across simulation iterations.
See Section~Y in the Supplementary Materials for further implementation details.

{\small
\bibliography{refnorm}
\bibliographystyle{unsrt}
}

\end{document}
