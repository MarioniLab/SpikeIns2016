\documentclass{article}
\usepackage{graphicx}
\usepackage[margin=2.5cm]{geometry}
\usepackage[labelfont=bf]{caption}
\usepackage{color}
\usepackage{xcite}
\usepackage{amsmath}
\usepackage{textcomp}

\renewcommand{\textfraction}{1.0}
\renewcommand{\floatpagefraction}{.9}
\newcommand\revised[1]{\textcolor{red}{#1}}
\renewcommand{\topfraction}{0.9}    % max fraction of floats at top
\renewcommand{\bottomfraction}{0.8} % max fraction of floats at bottom
\renewcommand{\textfraction}{0.07}  % allow minimal text w. figs

\makeatletter 
\renewcommand{\fnum@figure}{Supplementary \figurename~\thefigure}
\renewcommand{\fnum@table}{Supplementary \tablename~\thetable}
\makeatother

%\renewcommand{\thefigure}{\@arabic\c@figure} 
%\renewcommand{\thetable}{\@arabic\c@table} 

\externalcitedocument{prickle}

\usepackage{url}
\urlstyle{same}

\begin{document}

\begin{titlepage}
\vspace*{3cm}
\begin{center}

{\LARGE
When normalization gets prickly: are spike-ins good enough for single-cell RNA sequencing data?
\par}

\vspace{0.75cm}

{\Large 
    \textsc{Supplementary Materials}
\par
}
\vspace{0.75cm}

\large
by


\vspace{0.75cm}
Aaron T. L. Lun$^{1}$ and John C. Marioni$^{1,2}$

\vspace{1cm}
\begin{minipage}{0.9\textwidth}
\begin{flushleft} 
$^1$Cancer Research UK Cambridge Institute, University of Cambridge, Li Ka Shing Centre, Robinson Way, Cambridge CB2 0RE, United Kingdom \\[6pt]
$^2$EMBL European Bioinformatics Institute, Wellcome Genome Campus, Hinxton, Cambridge CB10 1SD, United Kingdom \\[6pt]
\end{flushleft}
\end{minipage}

\vspace{1.5cm}
{\large \today{}}

\vspace*{\fill}
\end{center}
\end{titlepage}

\section{Decomposing the variance for log-ratios of spike-ins}

\subsection{Overview of basic definitions}
The first step of the experiment involves adding spike-in sets to each well of a microtiter plate.
(We will use ``well'' and ``cell'' interchangeably here, as each well contains one cell.)
Consider these definitions:
\begin{center}
    \begin{tabular}{l p{0.9\textwidth}}
$C_{t_s}$  & The concentration in molecules per unit of volume for transcript $t_s$ in spike-in set $s$. \\
$\eta_{is}$   & The volume of spike-in set $s$ added to well $i$. \\
$\zeta_{it_s}$ & The number of molecules for transcript $t_s$ of set $s$ added to $i$ during spike-in addition.
\end{tabular}
\end{center}
$\eta_{is}$ is a random variable that depends on the experimental precision of volume addition.
In contrast, $C_{t_s}$ is a constant that depends on the composition of the spike-in set $s$.
We also define $\zeta_{it_s} = C_{t_s}\eta_{is}$.

After the spike-in volumes are added together, library preparation is performed to convert RNA to cDNA prior to high-throughput sequencing.
Consider the following definitions:
\begin{center}
\begin{tabular}{l p{0.9\textwidth}}
$R_{t_s}$ & The ``baseline'' number of cDNA fragments generated from each molecule of $t_s$. \\
$\phi_{is}$ & The efficiency of cDNA generation in well $i$ for all transcripts of set $s$. \\
$\delta_{it_s}$ & The cDNA fragment-per-transcript molecule conversion rate for transcript $t_s$ in well $i$.
\end{tabular}
\end{center}
$R_{t_s}$ is a constant as it depends on the inherent properties of each transcript.
$\phi_{is}$ is a random variable that represents well-specific biases for each spike-in set.
These parameters are related by $\delta_{it_s} = R_{t_s} \phi_{is}$.

Finally, define $\nu_{ig}$ as the number of transcript molecules for gene $g$ in the cellular RNA for the cell in well $i$.
This is a random variable that includes the biological variability in gene expression.
Let $\delta_{ig}$ represent the cDNA fragment-per-transcript conversion rate for $g$ in $i$, which is also a random variable across wells.

All random variables are assumed to be independent unless they have been explicitly related by equalities, e.g., $\zeta_{it_s}$ and $\eta_{is}$.
This is justified by the fact that they describe separate processes in the protocol.
The other exception is that $\phi_{is}$ may not be independent between $s$, as capture efficiencies of different sets may be affected by the same factors in each well.
However, they are still independent of the other variables.

\subsection{Constructing the distribution of the total counts}
For spike-in sets $s=1, 2, \ldots$, the cDNA fragment-to-read conversion factor for each well is
\[
    \rho_i = \frac{N_i}{\sum_g \delta_{ig}\nu_{ig} + \sum_{t_1} \delta_{it_1} S_{it_1}  + \sum_{t_2} \delta_{it_2} S_{it_2} + \ldots} 
\]
where $N_i$ is the size of the library for well $i$.
This accounts for composition biases, e.g., when overexpression of one gene can take up more sequencing resources and suppress the coverage of other genes.
In contrast, for UMI data, the fragment-to-UMI conversion factor is simply $\rho_i = 1$ when sequencing is saturated.

The conditional expectation of the total read count across all transcripts in set $s$ for well $i$ is
\[
    \mu_{is} = \rho_i  \textstyle\sum_{t_s} \delta_{it_s} \zeta_{it_s} = \rho_i  \eta_{is} \phi_{is} \sum_{t_s} R_{t_s} C_{t_s} \;.
\]
The observed total $y_{is}$ is assumed to be log-normally distributed, conditional on the other parameters, i.e., 
\[
    \log y_{is} | \{ \eta_{is}, \phi_{is} \forall s \}, \{ \delta_{ig}, \nu_{ig} \forall g \} \sim \mathcal{N}(\log \mu_{is}, \sigma^2_{lib(s)})
\]
where $\sigma^2_{lib(s)}$ represents the variability due to sequencing of set $s$.
We consider that $\sigma^2_{lib(s)} = f(A_s)$ for some monotonic decreasing function $f$ of the abundance $A_s$ for $s$.
This models the decrease in variability with increasing abundance, a trend that is typically observed in analyses of sequencing count data.

For simplicity, we define $A_s = E(\log \mu_{is})$ rather than $A_s = \log \mu_{is}$.
This is an approximation as the variability should depend on the size of the total count within each well, rather than on its expectation across all wells.
Nonetheless, this approximation is useful as it simplifies the following derivations, by ensuring that we do not have to consider the effect of variability in $\eta_{is}$, $\phi_{is}$, etc. on the value of $\sigma^2_{lib(s)}$.
We also assume that the totals are conditionally independent between different spike-in sets.
We have already conditioned on well-specific biases, so any remaining variation due to random technical noise should be independent.

\subsection{Deriving the variance of the log-ratios upon separate addition}
Denote the log-ratio of the total counts between two spike-in sets $s=1, 2$ as $\theta_i = \log(y_{i1}/y_{i2})$ for well $i$.
Based on the distribution of the total counts, $\theta_i$ is conditionally distributed as
\[
    \theta_i |  \{ \eta_{is}, \phi_{is} \forall s \} \sim \mathcal{N}( \log \mu_{i1} - \log \mu_{i2}, \sigma^2_{lib(1)} + \sigma^2_{lib(2)} ) \;. 
\]
There is no dependence on $\delta_{ig}$ or $\nu_{ig}$ as these terms cancel out during calculation of $\theta_i$ for each well.
This can be illustrated by examining the conditional expectation for $\theta_i$, i.e.,
\begin{align*}
    E(\theta_i |  \{ \eta_{is}, \phi_{is} \forall s \})
    &= \log \mu_{ix} - \log \mu_{iy} \\
    &= \log \left( \frac{\rho_i \eta_{i1} \phi_{i1} \sum_{t_1} R_{t_1} C_{t_1}}{\rho_i \eta_{i2} \phi_{i2} \sum_{t_2} R_{t_2} C_{t_2}} \right) \\
    &= \log \eta_{i1} - \log \eta_{i2} +  \log (\phi_{i1} / \phi_{i2})  + Z \quad\mbox{for some constant } Z \;.
\end{align*}

Assume that both $\log \eta_{i1}$ and $\log \eta_{i2}$ are distributed with the same variance $\sigma^2_{vol}$.
The use of the same variance is justified by the fact that the same spike-in volume is added for both $s=1$ and $2$, such that the variability should be the same for both volumes.
This means that the variance of $\theta_i$ can be written as
\[
\mbox{var}(\theta_i) = 2\sigma_{vol}^2 + \sigma^2_{lib(1)} + \sigma^2_{lib(2)} + \mbox{var}(\log \psi_i)
% Easily derived using the law of total variances.
% Normal distribution for R_i is obvious, based on product of PDFs (int[ P(X=x|u)*P(u) du ] gives a exp(x^2), eventually, and you can work this out to validate the variance).
% Both claims tested in simulations (sample variances of normal distribution with normal mean match up with expected truth, no rejections on a Shapiro-Wilk test).
\]
where $\psi_i = \phi_{i1}/\phi_{i2}$.
This can be estimated as the sample variance of the log-ratios across all wells in the first experiment. 
For convenience in downstream statistical tests, it is helpful to assume that $\log \eta_{is}$ for each $s$ and $\log \psi_i$ are normally distributed.
This ensures that $\theta_i$ will also follow a normal distribution.

\subsection{Deriving the variance of the log-ratios with premixing}
In the second experiment, mixing of spike-in sets occurs beforehand such that addition is not variable.
More specifically, $\eta_{i1}=\eta_{i2}$ in each well such that they cancel out in calculating $\theta_i$ and do not contribute to the variance.
This means that the variance of the log-ratio (denoted here as $\theta_i'$) can be written as
\[
    \mbox{var}(\theta_i') = \sigma^2_{lib(1)} + \sigma^2_{lib(2)} + \mbox{var}(\log \psi_i)
\]
and can be estimated as the sample variance of the log-ratios in this experiment.
Subtraction of the estimated variance of $\theta_i'$ from that of $\theta_i$ from the first experiment can be used to obtain an estimate of $\sigma^2_{vol}$.
Note that this assumes that $E(\log \mu_{is})$ is the same for each spike-in set between the first and second experiments, i.e., the average count size for each set is the same between experiments.
This ensures that there are no abundance-related changes in the technical variability of each set, i.e., $ \sigma^2_{lib(1)} + \sigma^2_{lib(2)}$.
In general, this assumption is reasonable if premixing of the two sets is done in a 1:1 ratio (volume-by-volume) and the total added volume of premixed spike-in is equal to the total volume for separate additions in the first experiment.

% It's possible to do something more complicated with a Poisson sampling distribution that's conditional on the mean.
% You could use the general variance decomposition formula to get the variance of the total count (see Bowsher and Swain, 2012).
% This would account for the mean-variance relationship at low counts.
% However, it becomes intractable to solve for the variance of the log-ratio of counts.
% There is no apparent benefit to this complexity, given that the log-normal approximation is more than sufficient at large counts.

\subsection{Estimating the variance of the set-specific capture efficiency}
Some work is required to decompose the components of $\mbox{var}(\theta_i')$, in order to separate technical variability from the variability of the $\phi_{is}$ terms.
This can be done by splitting one of the spike-in sets into two halves.
Divide transcripts in $s=1$ into two halves $1_a$ and $1_b$.
Each transcript is assigned to one half such that the total count for each half is equal to the sum of counts for all assigned transcripts.
We assume that the average capture efficiency is the same for each half as all transcripts are taken from the same spike-in set.
This means that $\phi_{i1} = \phi_{i1_a} = \phi_{i1_b}$, such that the capture efficiency term cancels out in the calculation of the log-ratio $\theta_{i(1_{ab})}'$ between the total counts of the two halves.
Thus, the variance of the log-ratio will simplify to 
\[
    \mbox{var}(\theta_{i(1_{ab})}') = \sigma^2_{lib(1_a)} + \sigma^2_{lib(1_b)} \;.
\]
This is true for both premixed and separate-addition experiments, as there is no variability in the added volume between two halves of the same spike-in set, i.e.,  $\eta_{i1} = \eta_{i1_a} = \eta_{i1_b}$.
Now, consider the variance of the log-ratio of the total count for each half $s=1_a, 1_b$ to the second spike-in set $s=2$.
This is written as
\begin{align*}
    \mbox{var}(\theta_{i(1_a)}') &= \sigma^2_{lib(1_a)} + \sigma^2_{lib(2)} + \mbox{var}(\log \psi_i) \\
    \mbox{var}(\theta_{i(1_b)}') &= \sigma^2_{lib(1_b)} + \sigma^2_{lib(2)} + \mbox{var}(\log \psi_i) \;,
\end{align*}
using only the samples in the second premixed experiment where variability in volume addition need not be considered.
We now perform some basic arithmetic on the variances of the log-ratios:
\begin{align*}
    &\mbox{var}(\theta_{i(1_a)}') +  \mbox{var}(\theta_{i(1_b)}') - \mbox{var}(\theta_{i(1_{ab})}') = 2 [\sigma^2_{lib(2)} + \mbox{var}(\log \psi_i)] \\
    &\mbox{var}(\theta_i') - \textstyle\frac{1}{2}[\mbox{var}(\theta_{i(1_a)}') + \mbox{var}(\theta_{i(1_b)}') - \mbox{var}(\theta_{i(1_{ab})}') ] = \sigma^2_{lib(1)}
\end{align*}
We repeat this after splitting $s=2$ into halves to obtain an estimate of $\sigma^2_{lib(2)}$.
These values can be subtracted from $\mbox{var}(\theta_i')$ to estimate the variance in the fold-differences in spike-in-specific efficiency, i.e., $\mbox{var}(\log \psi_i)$.

Note that our calculations assume that there is no variability in capture efficiency between the two halves of each spike-in set.
This may not be true of synthetic sets with few transcripts (e.g., 92 in ERCC, 7 in SIRV) where transcript-specific efficiencies may not average out within each half.
If variability in efficiency exists between halves, it will not cancel out when calculating $\theta_{i(1_{ab})}'$.
This is likely to result in overestimation of $\sigma^2_{lib(s)}$ and underestimation of the variance in spike-in-specific efficiency.
To mitigate this effect, we split the transcripts so that the distribution of transcript abundances is similar between halves.
This increases the chance that each half will have similar average efficiencies.
The value of $\mbox{var}(\theta_i')$ can also be treated as an upper bound for $\mbox{var}(\log \psi_i)$, reached when technical variability is absent, i.e., $\sigma^2_{lib(s)}=0$ for both $s=1,2$.

% Imagine that var(theta_i(ab)') is increased by x; this means that the true value of the estimated sigma^2_lib1 is actually sigma^2_lib1 + x.
% Hence, overestimation; assuming that the variability in behaviour relative to the second spike-in set doesn't change (which is why we have 'likely' not 'certainly').

\section{Implementation details for the downstream analyses}

\subsection{Data pre-processing}
Quality control was performed by removing libraries with outlier values for various quality metrics \cite{lun2016step}, including 
the log-transformed total read count across all genes and the log-transformed total number of expressed genes, where small outliers were removed; 
and the proportion of reads mapped to spike-in transcripts or mitochondrial genes, where large outliers were removed.
Outlier values were defined as those that were more than three median absolute deviations away from the median value in the specified direction.
Genes were also removed if the average count across all cells was below 1.
This filters out low-abundance genes that do not contain much information for stable inference.
For the data sets generated here, only the ERCC spike-in transcripts were used in the analyses below.
Counts for the SIRV transcripts were discarded for simplicity.

\subsection{Methods for detecting differentially expressed genes}
For DEG detection with edgeR v3.16.3, a NB GLM was fitted to the counts for each gene \cite{mccarthy2012differential} using a suitable design matrix.
The log-transformed total count for the spike-in transcripts was used as the offset for each library.
An abundance-dependent trend was fitted to the NB dispersions of all genes using the estimateDisp function.
Empirical Bayes shrinkage was performed towards this trend to obtain a shrunken NB dispersion for each gene.
The likelihood ratio test was applied to test for significant differences in expression between conditions for each gene. 
Finally, the Benjamini-Hochberg correction was applied to control the FDR.

For MAST v1.0.5, counts in each library were scaled so that the coverage of the spike-in transcripts was identical across libraries.
The scaled counts were converted to counts-per-million values, which were log-transformed after adding a pseudo-count of 1.
For each gene, a hurdle model was fitted to the log-CPMs across all cells using the zlm.SingleCellAssay function with default parameters.
Along with the experimental factors, the proportion of genes with non-zero counts in each library was included as a covariate \cite{finak2015mast} in the model.
Putative DE genes between the relevant conditions were identified using the lrTest function.

\subsection{Methods for detecting highly variable genes}
The first approach to detect HVGs is based on the method described by Brennecke \textit{et al.} \cite{brennecke2013accounting}.
The only modification involves defining the spike-in total (rescaled to have a mean of unity) as the size factor for each library, for both the endogenous and spike-in counts.
This represents spike-in normalization as it scales the counts in each library so that the spike-in totals are the same. 
We do \textit{not} compute separate size factors for the endogenous genes and spike-in transcripts, as this would require the use of non-DE normalization methods.
The rest of the method was implemented as originally described, using the technicalCV2 function in the scran package.
If blocking factors were present in the data set, they were regressed out by applying the removeBatchEffect function from the limma package to the counts, prior to using technicalCV2.

The second approach to detect HVGs is based on computing the variance of log-expression values \cite{lun2016step}.
A normalized log-expression value was defined as the log-ratio of each count with the spike-in-based size factor for the corresponding library
    (a pseudo-count of 1 was added prior to log-transformation to avoid undefined values).
The variance of the log-expression was computed across all cells for each spike-in transcript.
A loess curve was then fitted to the log-variance against the mean for all spike-in transcripts using the trendVar function in scran.
This represents the mean-variance relationship due to technical noise.
The biological component of the variance and a $p$-value was computed for each gene using the decomposeVar function.
If blocking factors were present, they were used to construct a design matrix for modelling in trendVar.

\subsection{Methods for dimensionality reduction and clustering}
For the mESC culture study, data was obtained from \url{http://www.ebi.ac.uk/teichmann-srv/espresso} \cite{kolod2015single}.
Counts were only used from the third batch of samples in which ERCC spike-ins were added.
Low-abundance genes were filtered out as previously described.
Cell-level quality control was already done and not required.

For construction of the PCA plot, normalized log-expression values were defined as previously described.
These values were supplied to the prcomp function with scaling and centering, and the first two principal components were used as the coordinates for each cell.
This was repeated for each simulation iteration after re-normalizing with the modified spike-in totals.
Coordinates of all cells in each simulated PCA plot were then mapped to the space of the original plot.
This was done by rotating and scaling the former to minimize the sum of squared Euclidean distances between the rotated and original coordinates.
After several simulation iterations, each cell has one original location and several remapped locations (one from each iteration). 
For each cell, the smallest circle centered at its original location was drawn that contained the corresponding remapped locations for 95\% of the iterations.
This circle acts like an ``error bar'' for the coordinates.

For clustering, a matrix of Euclidean distances was computed between pairs of cells using their normalized log-expression values.
Complete-linkage hierarchical clustering was then performed using the hclust function.
From the resulting dendrogram, the children of each node were defined as a possible cluster, referred to here as an original cluster.
Dendrogram construction was repeated after re-normalization in each simulation iteration.
The stability of each original cluster in response to spike-in variability was assessed as the proportion of iterations in which that cluster was present in the simulated dendrogram (i.e., all and only the cells in the cluster were the children of one node in that dendrogram).
This was repeated with a more relaxed criterion, where an original cluster was considered to be present in a simulated dendrogram if the lowest (i.e., furthest from the root) node containing all cells in the original cluster contained no more than 5\% of other cells.
This entire process was also repeated using 1 minus the rank correlations between cells as the distance.

\newpage
\section{Dealing with variable spike-in behaviour}
Another implicit assumption is that the spike-in populations exhibit equivalent behaviour with respect to cDNA generation efficiency.
This allows $\psi_i$ to cancel out during calculation of $R_i$, such that any variability in efficiency across wells can be ignored.
However, this may not be true for populations like the set of ERCC spike-ins with, e.g., differing GC composition, shorter poly-A tails.
Differences in well-specific efficiency can be modelled by introducing a $\psi_{is}$ term to replace $\psi_i$ in the above calculations.
This means that the conditional expectation of $R_i$ with respect to the random variables $V_{i}$ and $\psi_{is}$ becomes
\[
E(R_i | V_{ix}, V_{iy},  \psi_{ix}, \psi_{iy} ) = \log \frac{ S_{ix} \sum_t \psi_{ix}\delta_{t} \pi_{tx} } { S_{iy}\sum_t \psi_{iy}\delta_{t} \pi_{ty} } \;. \\
\]
The effect on the variance of $R_i$ depends on whether the ratio $\psi_{ix}/\psi_{iy}$ is constant or variable.
If it is constant, it will be absorbed into the constant term $Z$ and will not contribute to the variance across wells.
Otherwise, we can model $\log(\psi_{ix}/\psi_{iy})$ with a normal distribution that is independent of $V_{is}$.
The variance of this distribution will contribute directly to both $\mbox{var}(R_i)$ and $\mbox{var}(R_i')$, and will be effectively calculated as part of $\sigma^2_{lib}$.
Subtraction of sample variances will subsequently yield an estimate of $\sigma^2_{vol}$, as before.

Disentangling the variability of $\log(\psi_{ix}/\psi_{iy})$ from the other components of $\sigma^2_{lib}$ is more difficult.
It requires careful control over the properties of the spike-in populations -- namely, by using two populations that are effectively identical for the purposes of reverse transcription, yet sufficiently different for read alignment to the correct genome.
Some study of the relative contribution of this variance term can be performed by using several different spike-ins, and observing differences in the estimated $\sigma^2_{lib}$ (assuming that variance in the other steps of the protocol are constant across runs).
If the variance is negligible, then the exact value of $\psi_{ix}/\psi_{iy}$ is irrelevant in most applications as it will have no effect on the normalization factors between cells.

Another approach is to shuffle the spike-in sets \textit{in silico} for the second experiment.
Half the species in one set are summed with half the species in the other set, and this is repeated with the remaining species in both sets.
The variance of the log-ratios between these two sums is computed across wells, using the same partitioning of species for all wells.
To ensure robustness, a different partition can be chosen and the variance calculation repeated; the average variance can be computed across partitions.
The idea is that, on average, the shuffled populations do not exhibit any systematic difference in their capture efficiency.
Any variability in the log-ratio is attributable to the protocol alone, rather than changes to efficiency.
Subtracting from the original variance of the control experiment will identify the variability due to spike-in behaviour.

\newpage
\section{Statistical analyses of the results}
Denote the sample variance of $R$ as $s^2_1$, and that of $R'$ as $s^2_2$.
These are estimated from the set of observed ratios in each experiment, using the corrected Pearson estimator.
We could then intuitively define
\begin{align*}
\widehat{\sigma^2_{lib}} &= s^2_2 \quad\mbox{and} \\
\widehat{\sigma^2_{vol}} &= \frac{s^2_1 - s^2_2}{2} \;.
\end{align*}
However, this is not sensible if $s^2_1 < s^2_2$ as the estimate for $\sigma^2_{vol}$ will be negative.
In such cases, 
\begin{align*}
\widehat{\sigma^2_{vol}} &= 0 \quad\mbox{and} \\
\widehat{\sigma^2_{lib}} &= \frac{s^2_1(n_1 - 1) + s^2_2(n_2-1)}{n_1 + n_2 - 2} 
\end{align*}
where $n_1$ and $n_2$ are the number of repeated wells in the first and second experiments, respectively.
This uses all of the data from the first and second experiments to estimate $\sigma^2_{lib}$, while the estimate of $\sigma^2_{vol}$ is fixed at the lower bound of zero.
These definitions are based on the principle of restricted maximum likelihood when the parameter space is constrained to non-negative values (see Thompson, 1962).

% See "The Problem of Negative Estimates of Variance Components". Thompson (1962), Ann. Math. Statist., Volume 33, Number 1 (1962), 273-289.
% More specifically, the log-REML is equal to:
%\[
%L(\mathbf{y_1}, \mathbf{y_2} | \sigma^2_{lib}, \sigma^2_{vol}) = - n_1 \log(\sigma^2_{lib}) - \frac{1}{\sigma^2_{lib}} \sum y_{1i} - n_2 \log(\sigma^2_{lib} + \sigma^2_{vol}) - \frac{1}{\sigma^2_{lib} + \sigma^2_{vol}} \sum y_{2i} 
%\]
% where y_1 and y_2 are vectors of residual effects from the two experiments.
% If you take the partial derivatives with respect to each sigma^2, you get two equations that can be solved simultaneously.
% This yields a single maximum for the REML at the standard expressions for the experimental sample variances (and after subtraction, for the volume variance).
% However, the story's different when the volume variance estimate is forced to zero.
% Under normal conditions, there's only one maxima (see above) - but in this case, the maxima lies outside the constrained space.
% This means that the maxima in the constrained space must lie on the boundary, as the REML must increase as it gets closer to the maxima.
% We can then plug in a zero value for the volume variance and solve for the library variance, which gives us the value above. 

It is also possible to determine the significance of non-zero estimates for $\sigma^2_{vol}$.
This aims to determine whether there is a significant increase in variability from volume addition, over the variability introduced during general library preparation.
Specifically, the null hypothesis states that $\sigma^2_{vol} = 0$.
This means that
\begin{align*}
s^2_1 &\sim \frac{\sigma^2_{lib} \chi^2_{n_1 - 1}}{n_1 - 1} \quad\mbox{and} \\
s^2_2 &\sim \frac{\sigma^2_{lib} \chi^2_{n_2 - 1}}{n_2 - 1} 
\end{align*}
As the sample variances are estimated independently, the ratio $s^2_1/s^2_2$ follows a F-distribution on $n_1-1$ and $n_2-1$ degrees of freedom under the null.
The observed value of this ratio can be used to compute a $p$-value based on the upper tail of this distribution.
A similar test can be used to determine whether alterations in the protocol result in significant decreases in the variance, i.e., improvements in spike-in reliability.

Of course, these analyses hinge on the assumption of normality for the log-ratios. 
This can be evaluated empirically using established statistical methods such as the Shapiro-Wilk test.
Simulations indicate that the log-ratios of overdispersed count data can be accurately modelled with the normal distribution.

An alternative approach to variance estimation is to take the median absolute deviation (MAD) for each set of ratios and multiply it by 1.4826.
This will yield a robust, unbiased estimate of the standard deviation under normality.
While this protects against outliers, it will likely invalidate the tests described above -- the variance of this estimator will be different from the Pearson estimator.
Rather, it may be possible to use simulations to obtain a null distribution for the variance ratios.
For example, you could simulate the ratios of MAD-based variance estimates for the standard normal distribution.
The final distribution of these ratios should be the same even if you change the location or scale of the original normal distribution.

\newpage
\section{Estimating the variability of total cellular RNA}
Our aim is to estimate the variance of total cellular RNA, and to compare it to the variance of the spike-ins.
If the former is negligible compared to the latter, we can claim that any imprecision in spike-in addition will have little impact on the biological conclusions.
This suggests that spike-ins can be safely used.

To test this, we would ideally estimate $\mbox{var}(\sum_t \nu_{it})$, i.e., the variance in the number of cellular transcript molecules between wells/cells.
However, this not possible as we are confounded by the unknown efficiencies $\delta_{it}$. 
Thus, we instead consider the log-library size $L_i$ for well $i$, which has the conditional distribution
\[
L_i | V_{ix}, V_{iy}, \psi_i, \nu_{i1}, \ldots, \nu_{in} \sim \mathcal{N}(\log ( \rho_i \textstyle\sum_t \delta_{it} \nu_{it}), \sigma^2_{lib}) \;.
\]
Again, $\sigma^2_{lib}$ represents variability due to sequencing.
We assume that the conditional distribution of $L_i$ is independent of the conditional distributions for $y_{ix}$ and $y_{iy}$, i.e., sampling during sequencing is independent.
We define the normalized log-library size by subtracting the log-total of the spike-in counts, i.e., $\tilde{L_i} = L_i - \log y_{ix}$.
Here, we have chosen population $x$, though $y$ can also be used.
$\tilde{L_i}$ has the conditional distribution
\[
\tilde{L_i} | V_{ix}, V_{iy}, \psi_i, \nu_{i1}, \ldots, \nu_{in} \sim \mathcal{N}( \log S_{ix} + \log(\textstyle\sum_t \delta_t \pi_{tx}) - \log(\textstyle\sum_t \delta_t \nu_{it}), 2\sigma^2_{lib})
\]
which no longer depends on $V_{iy}$ or $\psi_i$.
Now, recall that $\log V_{ix}$ is normally distributed, such that 
\[
\tilde{L_i} | \nu_{i1}, \ldots, \nu_{in} \sim \mathcal{N}( E(\log V_{ix}) + \log C_{x} + \log(\textstyle\sum_t \delta_t \pi_{tx}) - \log(\textstyle\sum_t \delta_t \nu_{it}), 2\sigma^2_{lib} + \sigma^2_{vol}) \;.
\]
We further assume that $\log(\textstyle\sum_t \delta_t \nu_{it})$ is normally distributed with variance $\sigma^2_{bio}$.
This variance represents the biological variability in the expected number of reads, which can be used as a proxy for the variability in the number of transcript molecules.
Indeed, one could argue that the former is more relevant than the latter --  sequencing returns results in terms of reads, not transcripts, and even UMI-based methods fail to capture all transcript molecules.
With the above assumption, $\tilde{L_i}$ becomes normally distributed with variance
\[
\mbox{var}(\tilde{L_i}) = 2\sigma^2_{lib} + \sigma^2_{vol} + \sigma^2_{bio} \;.
\]
Statistical methods can then be applied to estimate the value of $\sigma^2_{bio}$ from the sample variance of $\tilde{L_i}$ across cells/wells.
This can be compared to $\sigma^2_{vol}$ to determine the relative importance of spike-in variability.

% Note that under the null, i.e., vol=bio, the variance of L_i should be equal to that of R_i.
% However, testing is complicated by the fact that we're using population 'x' twice in each well, to compute L_i and R_i.
% We'd end up with some correlation in the variance estimates, which would be pretty annoying.
% This isn't easily resolved; L_i and R_i are normally distributed, but y_ix and company are not (e.g., the denominator of rho_i consists of sum of log-normals, at best).
% I guess we could get independence by splitting the wells into two groups, computing L_i from one group and R_i from the other, and using that for testing. 
% We can probably afford to do this if we have enough wells to play around with (96 per plate?).


\begin{figure}[btp]
    \begin{center}
        \includegraphics[width=0.49\textwidth,trim=0mm 5mm 0mm 5mm,clip]{../real/pics/qq_separate.pdf}
        \includegraphics[width=0.49\textwidth,trim=0mm 5mm 0mm 5mm,clip]{../real/pics/qq_premixed.pdf}
    \end{center}
    \caption{Quantile-quantile plots of the log-ratios after separate addition of spike-ins (left) or premixed addition (right).
        For each plate, a linear model was fitted to the log-ratios to account for the experimental design.
        Residuals were standardized and plotted against the theoretical quantiles of a standard normal distribution.
        The dotted line represents equality between the sample and theoretical quantiles.
    }
\end{figure}

\begin{figure}[btp]
    \begin{center}
        \includegraphics[width=0.49\textwidth,trim=0mm 5mm 0mm 5mm,clip]{../real/pics/total_ercc.pdf}
        \includegraphics[width=0.49\textwidth,trim=0mm 5mm 0mm 5mm,clip]{../real/pics/total_sirv.pdf}
    \end{center}
    \caption{Distribution of the total number of reads assigned to transcripts in the ERCC (left) or SIRV spike-in set (right) across wells.
        For each plate, separate boxplots are shown for wells in which spike-ins were added separately or premixed before addition.
        Dots represent wells with total counts that are more than 1.5 interquartile ranges from the first or third quartile.
    }
\end{figure}

\begin{figure}[btp]
    \begin{center}
        \includegraphics[width=0.7\textwidth,trim=0mm 10mm 0mm 10mm,clip]{../real/pics/variance_order.pdf}
    \end{center}
    \caption{Estimated variance of the log-ratio of total counts between spike-in sets, computed across wells in which the ERCC spike-in set was added before the SIRV set or vice versa.
        This exploits the presence of a number of wells in each plate for which the order of spike-in addition was reversed.
        Error bars represent standard errors of the variance estimates under normality.
    }
\end{figure}

\begin{figure}[btp]
    \begin{center}
        \includegraphics[width=0.49\textwidth,trim=0mm 10mm 0mm 10mm,clip,page=1]{../sequence_check/biophysical/comparison.pdf}
        \includegraphics[width=0.49\textwidth,trim=0mm 10mm 0mm 10mm,clip,page=2]{../sequence_check/biophysical/comparison.pdf}
    \end{center}
    \caption{Biophysical properties of transcripts in each of the two spike-in sets and for 2000 randomly selected transcripts from the mouse mm10 genome.
    Boxplots are shown for the distribution of lengths and GC contents of transcripts (not including the poly-A tail) in each set.
}
\end{figure}

\end{document}


